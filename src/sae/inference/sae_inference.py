# src/sae/inference/sae_predict_dataloader.py

import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../")))

import torch
import pandas as pd
from tqdm import tqdm
from src.sae.model.sae import SAEClassifier
from src.sae.utils.embedding import get_bert_embeddings

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
test_df = pd.read_csv("data/test.csv")
test_df.columns = test_df.columns.str.strip()
texts = test_df["paragraph_text"].tolist()
ids = test_df["ID"].tolist()

# 2. BERT ì„ë² ë”© ì¶”ì¶œ
features = get_bert_embeddings(texts, batch_size=32).to(DEVICE)

# 3. SAE ëª¨ë¸ ë¡œë”©
model = SAEClassifier(input_dim=768, latent_dim=128).to(DEVICE)
model.load_state_dict(torch.load("model/sae_model.pt", map_location=DEVICE))
model.eval()

# 4. ì¶”ë¡ 
predictions = []
with torch.no_grad():
    for i in tqdm(range(0, len(features), 256), desc="ğŸ” ì¶”ë¡  ì¤‘"):
        batch = features[i:i+256]
        logits, _ = model(batch)
        preds = torch.argmax(logits, dim=1)
        predictions.extend(preds.cpu().tolist())

# 5. ê²°ê³¼ ì €ì¥
result_df = pd.DataFrame({
    "ID": ids,
    "generated": predictions
})

result_df.to_csv("result.csv", index=False)
print("âœ… result.csv ì €ì¥ ì™„ë£Œ")
