import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../")))

import torch
import pandas as pd
from tqdm import tqdm

from transformers import BertTokenizer, BertModel
from src.sae.model.sae import SAEClassifier
from src.sae.utils.embedding import get_bert_embeddings

# ë””ë°”ì´ìŠ¤ ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ë°ì´í„° ë¡œë”©
df = pd.read_csv("data/test.csv", encoding="utf-8-sig")
df.columns = df.columns.str.strip()
paragraphs = df["paragraph_text"].tolist()

# BERT ì„ë² ë”©
print("ğŸ”„ BERT ì„ë² ë”© ì¤‘...")
features = get_bert_embeddings(paragraphs, batch_size=4).to(DEVICE)

# SAE ëª¨ë¸ ë¡œë”©
model = SAEClassifier(input_dim=768).to(DEVICE)
model.load_state_dict(torch.load("model/sae_model.pt", map_location=DEVICE))
model.eval()

# ì˜ˆì¸¡
print("ğŸ” ì˜ˆì¸¡ ì¤‘...")
with torch.no_grad():
    logits, _ = model(features)
    preds = torch.argmax(logits, dim=1).cpu().numpy()

# ê²°ê³¼ ì €ì¥
result_df = pd.DataFrame({
    "ID": df["ID"],
    "generated": preds
})
result_df.to_csv("result.csv", index=False, encoding="utf-8-sig")

print("âœ… result.csv ì €ì¥ ì™„ë£Œ.")
